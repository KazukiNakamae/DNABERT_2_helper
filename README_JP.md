# DNABERT_2_helper

[English version](README.md)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[DNABERT-2](https://github.com/MAGICS-LAB/DNABERT_2)ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€è©•ä¾¡ã€ãƒ‡ãƒ—ãƒ­ã‚¤ã‚’æ”¯æ´ã™ã‚‹éå…¬å¼ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆé›†ã§ã™ã€‚

## æ¦‚è¦

DNABERT_2_helperã¯ã€ã‚²ãƒãƒ é…åˆ—åˆ†é¡ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦DNABERT-2ã‚’å®Ÿç”¨çš„ã«æ´»ç”¨ã™ã‚‹ãŸã‚ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¹ã‚¯ãƒªãƒ—ãƒˆé›†ã§ã™ã€‚ã“ã®ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã¯ã€**ã€ŒWorkflow for Fine-tuning and Evaluating DNA Language Models for Specific Genomics Issuesã€**ï¼ˆNakamae & Bono, Bio-protocol, 2025ï¼‰ã§è¨˜è¿°ã•ã‚ŒãŸãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®ä¸€éƒ¨ã¨ã—ã¦ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚

## æ©Ÿèƒ½

- ğŸ” **ç’°å¢ƒãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯**: GPU/CUDAãŠã‚ˆã³PyTorchè¨­å®šã®æ¤œè¨¼
- ğŸ”§ **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–**: åŠ¹ç‡çš„ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãŸã‚ã®ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒãƒ©ãƒƒãƒ‘ãƒ¼
- ğŸ“Š **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™**: ã‚µãƒ–ã‚»ãƒƒãƒˆä½œæˆã¨ãƒ©ãƒ™ãƒ«ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
- ğŸš€ **CPUå¯¾å¿œæ¨è«–**: GPUã‚’å¿…è¦ã¨ã—ãªã„Dockerãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡ç’°å¢ƒ
- ğŸ“ˆ **åŒ…æ‹¬çš„è©•ä¾¡**: æ­£è§£ç‡ã€F1ã€MCCã€é©åˆç‡ã€å†ç¾ç‡ã®è¨ˆç®—
- ğŸ¨ **å¯è¦–åŒ–**: ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚’æ¯”è¼ƒã™ã‚‹è«–æ–‡æ²è¼‰å“è³ªã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆ

## å¿…è¦è¦ä»¶

### ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ï¼ˆGPUç’°å¢ƒï¼‰
- CUDAå¯¾å¿œNVIDIA GPUï¼ˆH100 80GBã§ãƒ†ã‚¹ãƒˆæ¸ˆã¿ï¼‰
- CUDA Toolkit 12.1ä»¥ä¸Š
- Python 3.8ä»¥ä¸Š
- 120GBä»¥ä¸Šã®RAMï¼ˆæ¨å¥¨ï¼‰
- Ubuntu 22.04 LTSã¾ãŸã¯é¡ä¼¼ç’°å¢ƒ

### æ¨è«–ç”¨ï¼ˆCPUç’°å¢ƒï¼‰
- Docker
- 16GBä»¥ä¸Šã®RAMï¼ˆæ¨å¥¨ï¼‰
- macOSã¾ãŸã¯Linux

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

### 1. ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³

```bash
git clone https://github.com/KazukiNakamae/DNABERT_2_helper.git
cd DNABERT_2_helper
```

### 2. GPUç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ï¼‰

ãƒ—ãƒ­ãƒˆã‚³ãƒ«è«–æ–‡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³B1ã«è¨˜è¼‰ã•ã‚ŒãŸè©³ç´°ãªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †ã«å¾“ã£ã¦ãã ã•ã„ã€‚ä¸»ãªæ‰‹é †ï¼š

```bash
# condaç’°å¢ƒã®ä½œæˆ
conda create -n dna conda-forge::python=3.8
conda activate dna

# CUDAå¯¾å¿œPyTorchã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# è¿½åŠ ã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip3 install -r modified_requirements.txt

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œ
bash gpu_cuda_health_check.sh
python torch_health_check.py
```

### 3. CPUç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆæ¨è«–ç”¨ï¼‰

```bash
# CPUè©•ä¾¡ç”¨Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ“ãƒ«ãƒ‰
docker buildx build --platform linux/amd64 \
  --build-arg ENABLE_CUDA=0 \
  -t kazukinakamae/dnabert-eval:amd64 \
  -f Dockerfile .

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
mkdir -p .hf_cache
```

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒä»¥ä¸‹ã®CSVå½¢å¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š
- `train.csv`, `dev.csv`, `test.csv`
- å¿…é ˆã‚«ãƒ©ãƒ : `sequence`ï¼ˆDNAé…åˆ—ï¼‰, `label`ï¼ˆ0ã¾ãŸã¯1ï¼‰

### 2. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ

```bash
bash grid_search_train_wrapper.sh \
  --train_script train.py \
  --data_path /path/to/dataset \
  --model_name_or_path zhihan1996/DNABERT-2-117M \
  --output_root /path/to/output \
  --run_name_prefix my_experiment \
  --nproc_per_node 1 \
  --batch_configs "8x8,16x8,32x8" \
  --lrs "1e-5,2e-5" \
  --epochs "2" \
  --warmup_ratios "0.05,0.1" \
  --weight_decays "0.01,0.03" \
  --extra_args "--kmer -1 --model_max_length 10 --fp16"
```

### 3. æœ€é©ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é¸æŠ

```bash
python select_best_run.py \
  --output_root /path/to/grid_search_output \
  --metric_name eval_loss \
  --metric_mode min \
  --num_train_epochs 8 \
  --print_full_command
```

### 4. ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

[Northwestern University MAGICS Labsã«ã‚ˆã‚‹å…¬å¼ãƒªãƒã‚¸ãƒˆãƒª](https://github.com/MAGICS-LAB/DNABERT_2)ã‚’ã”å‚ç…§ãã ã•ã„ã€‚

### 5. æ¨è«–ã®å®Ÿè¡Œ

```bash
docker run --platform=linux/amd64 --rm \
  -v $(pwd):/DATA -w /DATA \
  -v $(pwd)/.hf_cache:/root/.cache/huggingface \
  kazukinakamae/dnabert-eval:amd64 \
  python predict_hf_classifier_csv.py \
    --model_dir /path/to/fine_tuned_model \
    --input_file test.csv \
    --output_file predictions.csv \
    --text_column sequence \
    --max_length 10 \
    --batch_size 32
```

### 6. æ€§èƒ½è©•ä¾¡

```bash
docker run --platform=linux/amd64 --rm \
  -v $(pwd):/DATA -w /DATA \
  kazukinakamae/dnabert-eval:amd64 \
  python evaluate_predictions_csv.py \
    --gold_file test.csv \
    --pred_file predictions.csv \
    --out_prefix eval_results \
    --gold_label_column label \
    --pred_label_column pred_label \
    --average macro \
    --pos_label 1
```

### 7. çµæœã®å¯è¦–åŒ–

```bash
# è¤‡æ•°ã®å®Ÿé¨“ã‹ã‚‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’çµ±åˆ
docker run --platform=linux/amd64 --rm \
  -v $(pwd):/DATA -w /DATA \
  kazukinakamae/dnabert-eval:amd64 \
  python merge_metrics_csvs.py \
    --input_glob "eval_summary/**/*_metrics.csv" \
    --recursive \
    --out_csv merged_metrics.csv

# ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®ç”Ÿæˆ
docker run --platform=linux/amd64 --rm \
  -v $(pwd):/DATA -w /DATA \
  kazukinakamae/dnabert-eval:amd64 \
  python plot_heatmaps_from_merged.py \
    --input_csv merged_metrics.csv \
    --outdir eval_summary \
    --dpi 500 \
    --formats png,tiff,pdf \
    --annotate
```

## ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

### ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

#### `gpu_cuda_health_check.sh`
OSãƒ¬ãƒ™ãƒ«ã§ã®GPUã¨CUDAã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã®æ¤œè¨¼ã€‚

```bash
bash gpu_cuda_health_check.sh
```

#### `torch_health_check.py`
PyTorchãŒGPUã‚’åˆ©ç”¨å¯èƒ½ã‹ç¢ºèªã€‚

```bash
python torch_health_check.py
```

### ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

#### `subset_dataset_csv.py`
ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã‚„ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ä½œæˆã€‚

```bash
python subset_dataset_csv.py \
  --input_dir /path/to/dataset \
  --output_dir /path/to/subset \
  --subset_ratio 0.2 \
  --seed 1 \
  --label_column label
```

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³:**
- `--input_dir`: train.csv, dev.csv, test.csvã‚’å«ã‚€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
- `--output_dir`: ã‚µãƒ–ã‚»ãƒƒãƒˆå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
- `--subset_ratio`: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆï¼ˆ0.0-1.0ï¼‰
- `--seed`: å†ç¾æ€§ã®ãŸã‚ã®ä¹±æ•°ã‚·ãƒ¼ãƒ‰
- `--label_column`: ãƒ©ãƒ™ãƒ«ã‚«ãƒ©ãƒ ã®åå‰

### ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

#### `grid_search_train_wrapper.sh`
DNABERT-2ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãŸã‚ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã‚’è‡ªå‹•åŒ–ã€‚

```bash
bash grid_search_train_wrapper.sh \
  --train_script train.py \
  --data_path /path/to/dataset \
  --model_name_or_path zhihan1996/DNABERT-2-117M \
  --output_root /path/to/output \
  --run_name_prefix experiment \
  --nproc_per_node 1 \
  --batch_configs "8x8,16x8" \
  --lrs "1e-5,2e-5" \
  --epochs "2,4" \
  --warmup_ratios "0.05,0.1" \
  --weight_decays "0.01,0.03" \
  --extra_args "--kmer -1 --model_max_length 10 --fp16"
```

**ä¸»è¦ã‚ªãƒ—ã‚·ãƒ§ãƒ³:**
- `--batch_configs`: "ãƒãƒƒãƒã‚µã‚¤ã‚º x å‹¾é…ç´¯ç©ã‚¹ãƒ†ãƒƒãƒ—"å½¢å¼
- `--lrs`: ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®å­¦ç¿’ç‡
- `--epochs`: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒãƒƒã‚¯æ•°
- `--warmup_ratios`: ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æ¯”ç‡ã¾ãŸã¯ã‚¹ãƒ†ãƒƒãƒ—æ•°
- `--weight_decays`: é‡ã¿æ¸›è¡°å¼·åº¦

#### `select_best_run.py`
ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒçµæœã‹ã‚‰æœ€é©ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ„ã¿åˆã‚ã›ã‚’ç‰¹å®šã€‚

```bash
python select_best_run.py \
  --output_root /path/to/grid_output \
  --metric_name eval_loss \
  --metric_mode min \
  --num_train_epochs 8 \
  --print_full_command
```

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³:**
- `--metric_name`: æœ€é©åŒ–ã™ã‚‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆeval_lossã€accuracyã€f1ãªã©ï¼‰
- `--metric_mode`: "min"ã¾ãŸã¯"max"
- `--print_full_command`: å³å®Ÿè¡Œå¯èƒ½ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒãƒ³ãƒ‰ã‚’ç”Ÿæˆ

#### `resume_same_task_same_data.py`
ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å†é–‹ã€‚

```bash
python resume_same_task_same_data.py \
  --checkpoint_dir /path/to/checkpoint \
  --data_path /path/to/dataset \
  --output_dir /path/to/output \
  --add_epochs 4 \
  --do_test_eval
```

### ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

#### `onehot_cnn_baseline.py`
3å±¤one-hot CNNãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã€‚

```bash
python onehot_cnn_baseline.py \
  --train_csv train.csv \
  --dev_csv dev.csv \
  --test_csv test.csv \
  --outdir baseline_output \
  --seq_len 700 \
  --epochs 30 \
  --batch_size 128 \
  --lr 1e-3 \
  --weight_decay 1e-4
```

#### `predict_motif_baseline_csv.py`
ãƒ¢ãƒãƒ¼ãƒ•ãƒ™ãƒ¼ã‚¹ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã‚’ç”Ÿæˆã€‚

```bash
python predict_motif_baseline_csv.py \
  --input test.csv \
  --output motif_predictions.csv \
  --pattern WCW \
  --start 19
```

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³:**
- `--pattern`: ãƒ¢ãƒãƒ¼ãƒ•ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¾‹: WCWã€ACWï¼‰
- `--start`: ãƒ¢ãƒãƒ¼ãƒ•ãƒãƒƒãƒãƒ³ã‚°ã®0å§‹ã¾ã‚Šé–‹å§‹ä½ç½®

### æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

#### `predict_hf_classifier_csv.py`
ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿DNABERT-2ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦äºˆæ¸¬ã‚’ç”Ÿæˆã€‚

```bash
python predict_hf_classifier_csv.py \
  --model_dir /path/to/model \
  --input_file test.csv \
  --output_file predictions.csv \
  --text_column sequence \
  --max_length 10 \
  --batch_size 32 \
  --trust_remote_code
```

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³:**
- `--model_dir`: ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®ãƒ‘ã‚¹
- `--text_column`: é…åˆ—ã‚’å«ã‚€ã‚«ãƒ©ãƒ å
- `--max_length`: ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã•ã‚ŒãŸé…åˆ—ã®æœ€å¤§é•·
- `--batch_size`: æ¨è«–ãƒãƒƒãƒã‚µã‚¤ã‚º

#### `predict_onehot_cnn_csv.py`
è¨“ç·´æ¸ˆã¿one-hot CNNãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã§æ¨è«–ã‚’å®Ÿè¡Œã€‚

```bash
python predict_onehot_cnn_csv.py \
  --model best_model.pt \
  --input test.csv \
  --output cnn_predictions.csv \
  --batch_size 256 \
  --device cpu
```

### è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

#### `evaluate_predictions_csv.py`
åˆ†é¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—ã€‚

```bash
python evaluate_predictions_csv.py \
  --gold_file test.csv \
  --pred_file predictions.csv \
  --out_prefix results \
  --gold_label_column label \
  --pred_label_column pred_label \
  --average macro \
  --pos_label 1
```

**å‡ºåŠ›:**
- `{out_prefix}_metrics.csv`: æ­£è§£ç‡ã€F1ã€MCCã€é©åˆç‡ã€å†ç¾ç‡
- `{out_prefix}_confusion.png`: æ··åŒè¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—

#### `filter_evalres_seq_label.py`
äºˆæ¸¬çµæœã«åŸºã¥ã„ã¦ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€‚

```bash
python filter_evalres_seq_label.py \
  --input predictions.csv \
  --output filtered_test.csv \
  --pred-value 0
```

**ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹:** è©³ç´°åˆ†æã®ãŸã‚ã®éãƒ¢ãƒãƒ¼ãƒ•é…åˆ—ã®æŠ½å‡º

### å¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

#### `merge_metrics_csvs.py`
è¤‡æ•°ã®å®Ÿé¨“ã‹ã‚‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’é›†ç´„ã€‚

```bash
python merge_metrics_csvs.py \
  --input_glob "eval_summary/**/*_metrics.csv" \
  --recursive \
  --rep_regex "(?:^|/|_)(?:rep|repeat|r)(?P<rep>\\d+)(?:/|_|$)" \
  --out_csv merged_metrics.csv
```

#### `plot_heatmaps_from_merged.py`
è«–æ–‡æ²è¼‰å“è³ªã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ç”Ÿæˆã€‚

```bash
python plot_heatmaps_from_merged.py \
  --input_csv merged_metrics.csv \
  --outdir figures \
  --dpi 500 \
  --formats png,tiff,pdf \
  --agg mean \
  --baseline_model cnn_baseline \
  --draw_baseline_separator \
  --annotate
```

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³:**
- `--agg`: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ãƒˆã®é›†ç´„æ–¹æ³•ï¼ˆmeanã€medianï¼‰
- `--baseline_model`: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒã‚’å¼·èª¿
- `--annotate`: ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚»ãƒ«ã«ãƒ¡ãƒˆãƒªãƒƒã‚¯å€¤ã‚’è¡¨ç¤º

## ä½¿ç”¨ä¾‹

### ä¾‹1: RNAã‚ªãƒ•ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬

```bash
# 1. PiCTUREãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ï¼ˆãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³A1å‚ç…§ï¼‰
# å‡ºåŠ›: FD1/dataset_v1_union_40bp_balanced/

# 2. ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒç”¨ã®ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ä½œæˆ
python subset_dataset_csv.py \
  --input_dir FD1/dataset_v1_union_40bp_balanced \
  --output_dir FD1/dataset_subset20 \
  --subset_ratio 0.2 \
  --seed 1 \
  --label_column label

# 3. ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ
bash grid_search_train_wrapper.sh \
  --train_script train.py \
  --data_path FD1/dataset_subset20 \
  --model_name_or_path zhihan1996/DNABERT-2-117M \
  --output_root fd1_grid_output \
  --run_name_prefix fd1_rnaofftarget \
  --nproc_per_node 1 \
  --batch_configs "8x8,16x8,32x8" \
  --lrs "1e-5,2e-5" \
  --epochs "2" \
  --warmup_ratios "0.05,0.1" \
  --weight_decays "0.01,0.03" \
  --extra_args "--kmer -1 --model_max_length 10 --fp16"

# 4. æœ€é©ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é¸æŠ
python select_best_run.py \
  --output_root fd1_grid_output \
  --metric_name eval_loss \
  --metric_mode min \
  --num_train_epochs 8 \
  --print_full_command

# 5. æœ€é©ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆã‚¹ãƒ†ãƒƒãƒ—4ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ï¼‰

# 6. ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§è©•ä¾¡
docker run --platform=linux/amd64 --rm \
  -v $(pwd):/DATA -w /DATA \
  -v $(pwd)/.hf_cache:/root/.cache/huggingface \
  kazukinakamae/dnabert-eval:amd64 \
  python predict_hf_classifier_csv.py \
    --model_dir fd1_output \
    --input_file FD1/dataset_v1_union_40bp_balanced/test.csv \
    --output_file fd1_predictions.csv \
    --text_column sequence \
    --max_length 10 \
    --batch_size 32

# 7. ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—
docker run --platform=linux/amd64 --rm \
  -v $(pwd):/DATA -w /DATA \
  kazukinakamae/dnabert-eval:amd64 \
  python evaluate_predictions_csv.py \
    --gold_file FD1/dataset_v1_union_40bp_balanced/test.csv \
    --pred_file fd1_predictions.csv \
    --out_prefix fd1_eval \
    --gold_label_column label \
    --pred_label_column pred_label \
    --pos_label 1
```

### ä¾‹2: ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼åˆ†é¡

```bash
# 1. EPDnewã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ï¼ˆè«–æ–‡ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³A2å‚ç…§ï¼‰

# 2. ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ
bash grid_search_train_wrapper.sh \
  --train_script train.py \
  --data_path mammal_promoter_classifier/dataset_subset20 \
  --model_name_or_path zhihan1996/DNABERT-2-117M \
  --output_root mammal_promoter_grid \
  --run_name_prefix mammal_promoter \
  --nproc_per_node 1 \
  --batch_configs "8x8,16x8,32x8" \
  --lrs "1e-5,2e-5" \
  --epochs "2" \
  --warmup_ratios "0.05,0.1" \
  --weight_decays "0.01,0.03" \
  --extra_args "--kmer -1 --model_max_length 175 --fp16"

# 3. æ¯”è¼ƒç”¨ã®CNNãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’è¨“ç·´
python onehot_cnn_baseline.py \
  --train_csv mammal_promoter_classifier/dataset/train.csv \
  --dev_csv mammal_promoter_classifier/dataset/dev.csv \
  --test_csv mammal_promoter_classifier/dataset/test.csv \
  --outdir cnn_baseline \
  --seq_len 700 \
  --epochs 30

# 4. ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§çµæœã‚’æ¯”è¼ƒï¼ˆä¸¡ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œå¾Œï¼‰
python merge_metrics_csvs.py \
  --input_glob "eval_summary/**/*_metrics.csv" \
  --recursive \
  --out_csv merged_metrics.csv

python plot_heatmaps_from_merged.py \
  --input_csv merged_metrics.csv \
  --outdir figures \
  --baseline_model cnn_baseline \
  --annotate
```

## å¼•ç”¨

ç ”ç©¶ã§DNABERT_2_helperã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã‚’å¼•ç”¨ã—ã¦ãã ã•ã„ï¼š

```bibtex
@article{nakamae2025dnabert2helper,
  title={Workflow for Fine-tuning and Evaluating DNA Language Models for Specific Genomics Issues},
  author={Nakamae, Kazuki and Bono, Hidemasa},
  journal={Bio-protocol},
  year={2025},
  note={In press}
}
```

ã¾ãŸã€å…ƒã®DNABERT-2è«–æ–‡ã‚‚å¼•ç”¨ã—ã¦ãã ã•ã„ï¼š

```bibtex
@article{zhou2024dnabert2,
  title={DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genome},
  author={Zhou, Zhihan and Ji, Yanrong and Li, Weijian and Dutta, Pratik and Davuluri, Ramana and Liu, Han},
  journal={arXiv preprint arXiv:2306.15006},
  year={2024}
}
```

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚è©³ç´°ã¯[LICENSE](LICENSE)ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã”è¦§ãã ã•ã„ã€‚

## é–¢é€£ãƒªãƒ³ã‚¯

- [å…¬å¼DNABERT-2ãƒªãƒã‚¸ãƒˆãƒª](https://github.com/MAGICS-LAB/DNABERT_2)
- [PiCTUREãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³](https://github.com/KazukiNakamae/PiCTURE)
- [RNAOffScan](https://github.com/KazukiNakamae/RNAOffScan)
- [EPDnewãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹](https://epd.expasy.org/epd/)

## é€£çµ¡å…ˆ

è³ªå•ã‚„å•é¡Œã«ã¤ã„ã¦ã¯ï¼š
- GitHubã§Issueã‚’é–‹ã
- é€£çµ¡å…ˆ: kazuki-nakamae@hiroshima-u.ac.jp

---

**æ³¨è¨˜**: ã“ã‚Œã¯éå…¬å¼ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã§ã™ã€‚å…¬å¼ã®DNABERT-2å®Ÿè£…ã«ã¤ã„ã¦ã¯ã€[MAGICS-LABãƒªãƒã‚¸ãƒˆãƒª](https://github.com/MAGICS-LAB/DNABERT_2)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
